# Evaluation of Machine Learning Models

## Learning Objectives
* Describe Describe how overfitting is related to generalization
* Explain Explain why overfitting should be avoided
* Discuss Discuss overfitting in the context of decision tree models
* Explain Explain how overfitting is addressed in decision tree induction
* Define Define pre-pruning and post-pruning
* Describe Describe how a validation set can be used to avoid overfitting
* Express Articulate how training, validation, and test sets are used
* List List three ways that validation can be performed
* Discuss Discuss how performance metrics can be used to evaluate models
* Recall Name three model evaluation metrics
* Explain Explain why accuracy may be misleading
* Describe Describe how a confusion matrix can be used to evaluate a classifier
* Interpret Interpret the confusion matrix of a model
* Show Relate accuracy to values in a confusion matrix
* Practice Practice generating and interpreting metrics to evaluate a model

## Overfitting: What is it and how would you prevent it?
* [Generalization and Overfitting](./files/generalization_and_overfitting.pdf)
* [Overfitting Decision Trees](./files/overfitting_decision_trees.pdf)
* [Using a Validation Set](./files/using_a_validation_set.pdf)

## Model evaluation metrics and methods
* [Confussion Matrix](./files/confusion_matrix.pdf)
* [Evaluation Metrics](./files/evaluation_metrics.pdf)

## Readings
* [Completed KNIME WorkFlows](./files/CompletedKNIMEWorkflows.pdf)
* [Comparing Classification Results for KNIME and Spark](./files/ComparingClassificationResultsforKNIMEandSpark.pdf)
* [Evaluation of Decision Tree in KNIME](./files/EvaluationofDecisionTreeinKNIME.pdf)
* [Evaluation of Decision Tree in Spark](./files/EvaluationofDecisionTreeinSpark.pdf)
